anchors = json.load(open(paths['anchors'], 'r', encoding='utf-8'))
patterns = load_patterns(paths['patterns'])

# context-aware gazetteer extraction (uses anchors)
gaz_hits = extract_with_gazetteers(
    text,
    gazetteers=gaz,
    alias_maps=alias,
    anchors=anchors,
    anchor_window=windows['anchor_chars'],
    require_anchor=True   # set False if you want to allow context-free gaz hits
)


out = {
    'product': settings['product'],
    'overall_trust': round(sum(v['final_confidence'] for v in fields.values())/max(1,len(fields)), 3),
    'fields': fields,
    'trades': trades,
    'summary': summary_text
}

os.makedirs(os.path.dirname(args.out), exist_ok=True)

# NEW: Prodigy JSONL
prodigy_examples = build_prodigy_examples(text, fields, top_k_per_field=3)
prodigy_path = os.path.join(os.path.dirname(args.out), "prodigy.jsonl")
write_jsonl(prodigy_path, prodigy_examples)

# Original JSON
json.dump(out, open(args.out, 'w', encoding='utf-8'), indent=2, ensure_ascii=False)
print(f"Wrote {args.out}")
print(f"Wrote {prodigy_path}  # Load this in Prodigy")
