import yaml
from extractors.file_loader import load_and_normalize
from gazetteer_loader import load_gazetteers_from_json
from matchers.matcher import extract_with_gazetteers
from matchers.regex_patterns import patterns
from nlp.ai_fallback import run_ai_fallback
from resolver import resolve_candidates

def _add_cand(bucket, field, value, method, conf, source, span, snippet, extras=None):
    bucket.setdefault(field, []).append({
        "value": value, "method": method, "conf": conf,
        "source": source, "span": span, "snippet": snippet,
        "extras": extras or {}
    })

def run_pipeline(file_path_or_html, config_path):
    with open(config_path, "r", encoding="utf-8") as f:
        cfg = yaml.safe_load(f)

    # 1) normalize text
    text = load_and_normalize(file_path_or_html)

    # 2) gazetteers (common + product JSON)
    common_json = cfg["gazetteer_json"]["common"]
    product_json = cfg["gazetteer_json"]["product"]
    gazetteers, alias_maps, fuzzy_cfg, _ = load_gazetteers_from_json(common_json, product_json)

    # 3) gazetteer extraction
    gaz_hits = extract_with_gazetteers(text, gazetteers, alias_maps, fuzzy_cfg)

    candidates = {}
    for field, hits in gaz_hits.items():
        for h in hits:
            method = h.get("method", "gazetteer_exact")
            span = tuple(h["span"])
            snippet = text[max(0, span[0]-40): min(len(text), span[1]+40)]
            _add_cand(candidates, field, h["value"], method, h["confidence"], "TXT", span, snippet)

    # 4) pattern extraction (use YAML field groups)
    groups = cfg["field_groups"]
    cat_to_rx = {"dates":"date", "percents":"percent", "amounts":"amount_ccy", "currencies":"currency"}
    for cat, fields in groups.get("pattern_fields", {}).items():
        rx = patterns[cat_to_rx[cat]]
        for m in rx.finditer(text):
            span = (m.start(), m.end())
            snippet = text[max(0, span[0]-40): min(len(text), span[1]+40)]
            for field in fields:
                _add_cand(candidates, field, m.group(0), "regex_strong", 0.90, "TXT", span, snippet)

    # 5) AI fallback for unresolved
    resolved = set(candidates.keys())
    all_fields = set(groups.get("gazetteer_fields", []))
    for _cat, flds in groups.get("pattern_fields", {}).items():
        all_fields.update(flds)
    all_fields.update(groups.get("fallback_fields", []))
    unresolved = sorted(all_fields - resolved)

    ai_hits = run_ai_fallback(text, unresolved)
    for field, hits in ai_hits.items():
        for h in hits:
            span = tuple(h["span"])
            _add_cand(candidates, field, h["value"], h["method"], h["confidence"], h.get("source","TXT"), span, h.get("snippet",""))

    # 6) resolve to final
    fields = resolve_candidates(candidates)
    overall = round(sum(v["final_confidence"] for v in fields.values())/max(1,len(fields)), 3)

    return {"product": cfg.get("product"), "overall_trust": overall, "fields": fields, "raw_text": text}
